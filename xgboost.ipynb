{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5eed76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99916cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet('./preprocessed_datasets/dataset_alpha_0.4_full_binarytarget_win-24_thresh-19_both.parquet')\n",
    "dataset['timestamp'] = dataset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab5d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_COL = \"timestamp\"   \n",
    "TARGET_COL = \"target\"    \n",
    "df = dataset.copy()\n",
    "\n",
    "\n",
    "df[TIME_COL] = pd.to_datetime(df[TIME_COL])\n",
    "df = df.sort_values(TIME_COL).reset_index(drop=True)\n",
    "\n",
    "\n",
    "FEATURES = [c for c in df.columns if c not in [TIME_COL, TARGET_COL]]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_COL].astype(int)\n",
    "\n",
    "n = len(df)\n",
    "test_size = int(0.20 * n)\n",
    "val_size  = int(0.20 * (n - test_size))\n",
    "\n",
    "train_end = n - test_size\n",
    "val_end = train_end\n",
    "train_end2 = train_end - val_size\n",
    "\n",
    "X_train, y_train = X.iloc[:train_end2], y.iloc[:train_end2]\n",
    "X_val,   y_val   = X.iloc[train_end2:val_end], y.iloc[train_end2:val_end]\n",
    "X_test,  y_test  = X.iloc[val_end:], y.iloc[val_end:]\n",
    "\n",
    "\n",
    "# n_pos = (y_train == 1).sum()\n",
    "# n_neg = (y_train == 0).sum()\n",
    "# w_pos = (n_neg / max(n_pos, 1))\n",
    "\n",
    "# w_train = np.where(y_train.values == 1, w_pos, 1.0)\n",
    "# w_val   = np.where(y_val.values   == 1, w_pos, 1.0)\n",
    "# w_test  = np.where(y_test.values  == 1, w_pos, 1.0)  # only used if you want weighted metrics\n",
    "\n",
    "# print(f\"Train positives={n_pos}, negatives={n_neg}, w_pos={w_pos:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bal = (len(y)-sum(y))/sum(y)\n",
    "\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    scale_pos_weight=bal,      \n",
    "    random_state=1233,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,    \n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "print(\"Best iteration:\", model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe88347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "proba_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_test, proba_test)\n",
    "auprc = average_precision_score(y_test, proba_test)\n",
    "\n",
    "print(\"\\n=== Test Metrics ===\")\n",
    "print(f\"ROC AUC : {auc:.4f}\")\n",
    "print(f\"AUPRC   : {auprc:.4f}\")\n",
    "\n",
    "# Pick a threshold (0.5 default). Often for imbalance you may tune it.\n",
    "threshold = 0.50\n",
    "yhat_test = (proba_test >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, yhat_test)\n",
    "print(\"\\nConfusion matrix (threshold = %.2f):\\n%s\" % (threshold, cm))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, yhat_test, digits=4))\n",
    "\n",
    "# Plot ROC + PR curves\n",
    "fpr, tpr, _ = roc_curve(y_test, proba_test)\n",
    "prec, rec, _ = precision_recall_curve(y_test, proba_test)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax[0].plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n",
    "ax[0].plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "ax[0].set_title(\"ROC Curve\")\n",
    "ax[0].set_xlabel(\"False Positive Rate\")\n",
    "ax[0].set_ylabel(\"True Positive Rate\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(rec, prec, label=f\"AUPRC={auprc:.3f}\")\n",
    "ax[1].set_title(\"Precision-Recall Curve\")\n",
    "ax[1].set_xlabel(\"Recall\")\n",
    "ax[1].set_ylabel(\"Precision\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_explain = X_test.copy()\n",
    "if len(X_explain) > 5000:\n",
    "    X_explain = X_explain.sample(5000, random_state=42)\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_explain)  # shap.Explanation\n",
    "\n",
    "# Global importance (beeswarm)\n",
    "shap.plots.beeswarm(shap_values, max_display=25)\n",
    "\n",
    "# Bar plot of mean(|SHAP|)\n",
    "shap.plots.bar(shap_values, max_display=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
